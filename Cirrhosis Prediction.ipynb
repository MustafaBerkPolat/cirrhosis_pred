{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f743223-510f-44cd-8275-ae925ce29697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec320a36-b84a-4848-9f94-91d082de23bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cirrhosis = pd.read_csv(r'C:\\Users\\mpola\\OneDrive\\Desktop\\Career\\Proje\\Liver Cirrhosis Prediction\\data\\cirrhosis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bff52a0-93b3-4805-92d2-d97be63dcdf4",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942f97de-34b4-43c2-af6b-8c9094bed667",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "# To get a better idea of the dataset we are working with, it makes sense to use some functions to analyze the columns we have.\n",
    "\n",
    "\n",
    "# Padding the column names with spaces at the end so they look nicer once printed\n",
    "column_names = list(df_cirrhosis.columns)\n",
    "max_length = max(len(name) for name in column_names)\n",
    "\n",
    "formatted_names = []\n",
    "for name in column_names:\n",
    "    formatted_names.append(name + \" \" * (max_length - len(name)))\n",
    "\n",
    "\n",
    "# The skewness calculation shows that most columns' data is heavily skewed, so the distribution is not close to normal.\n",
    "# This makes using mean values to fill in NaN entries a poor choice, so we will use median instead.\n",
    "print('---Skewness Values of Numerical Columns---')\n",
    "print('| Column Name | Skewness |')\n",
    "print('|-------------|----------|')\n",
    "for index, col in enumerate(df_cirrhosis.columns):\n",
    "    if df_cirrhosis[col].dtype == 'float64' or df_cirrhosis[col].dtype == 'int64': \n",
    "        skewness = skew(df_cirrhosis[col], nan_policy='omit')\n",
    "        print(f'| {formatted_names[index]} | {skewness} |')\n",
    "\n",
    "# print('\\n\\n---Dataframe Head---')\n",
    "# print(df_cirrhosis.head(20))\n",
    "\n",
    "print('\\n\\n---Dataframe Info---')\n",
    "print(df_cirrhosis.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7af5cb-699b-4a3e-96bd-aba6ffb64eee",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print('\\n\\n---Dataframe Description---')\n",
    "print(df_cirrhosis.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8aebb4-23ff-408b-aca1-360ef3e47a9b",
   "metadata": {},
   "source": [
    "The max values for Cholesterol, Copper, Alk_Phos, Bilirubin and Tryglicerides columns  are anywhere between roughly 4 to 8 times higher than the 75% values, so there are plenty of outliers here. With the exception of Tryglicerides, these columns also have very high standard deviation values compared to their means, so the data seems to be very irregular in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42d1020-c567-4843-b1b7-52c0d1d0d964",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Defining the lists that contain numerical and categorical columns to use later\n",
    "\n",
    "numerical_cols = df_cirrhosis.select_dtypes(include=np.number).columns\n",
    "categorical_cols = df_cirrhosis.select_dtypes(include=('object')).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367c71b2-549a-4c42-a61d-f35fdc90af1a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df_cirrhosis[numerical_cols])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66012a0-24c3-40a6-a0f8-9454b7056973",
   "metadata": {},
   "source": [
    "At a first glance at the pair plots of our numerical data, there aren't any strong correlations or clustering to take into immediate consideration. It may seem like the inclusion of the ID column is an oversight, but looking closely, we can see that there is a very clear cut-off line for the N-Days column where its upper bound somewhat linearly decreases with ID until roughly the 300 ID mark, but then it resets and starts linearly decreasing again, and past this 300-ID line we have no data for some of the columns like Cholesterol, Copper and Alk_Phos. This is in line with the dataset description mentioning that the first 312 participants contain more complete data whereas the remaining 106 did not participate in the clinical trial of the drug D-penicillamine, only giving consent to basic measurements. This can cause our predictions to be biased or be performed with incomplete information, but given the size of the dataset, I chose not to exclude the last 106 participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5cb719-bbac-42bb-b156-5216ae22839d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "corr = df_cirrhosis[numerical_cols].corr(method = 'spearman')\n",
    "plt.figure(figsize = (15, 15), dpi = 300)\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(corr, mask = mask, annot = True, annot_kws = {'size' : 15})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd5c00a-4da1-4581-9e97-91c2407fcc46",
   "metadata": {},
   "source": [
    "This dataset has plenty of outliers and some non-normal distributed data, so when testing for correlation I elected to check the Spearman correlation coefficient. The N_Days feature has a somewhat positive correlation with Albumin, and negative correlations with Bilirubin, Copper and cirrhosis stage, but these correlations are not strong enough to consider dimensionality reduction solely based off of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa6b97e-ef5d-46be-8849-9166b3d8373d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_cirrhosis['Stage'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582bb7e7-8c91-4661-acca-4becd0f0d6ae",
   "metadata": {},
   "source": [
    "As we will be trying to predict the stage of cirrhosis using other info and the count of each stage is imbalanced, using log loss to evaluate model performance is our best approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4824785-e3e9-4393-bc84-d64f9722b8c9",
   "metadata": {},
   "source": [
    "### Data Preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c548a57-b1d8-43d8-a37f-772062f326aa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# There are both numerical and categorical data in this dataset, with a lot of blank entries and outliers. In order to\n",
    "# avoid problems with the prediction, we will be filling in the missing numerical data with the median values (as explained before) \n",
    "# and the missing categorical data with the mode values\n",
    "\n",
    "for col in numerical_cols:\n",
    "    # Using median of numerical columns to replace NaN values since this dataset contains outliers\n",
    "    df_cirrhosis[col] = df_cirrhosis[col].fillna(df_cirrhosis[col].median())\n",
    "\n",
    "for col in categorical_cols:\n",
    "    # Using mode of categorical columns to replace NaN values\n",
    "    df_cirrhosis[col] = df_cirrhosis[col].fillna(df_cirrhosis[col].mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81f5a28-1591-43b9-9302-b59bbe9220e3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#########################################################\n",
    "def detect_outliers_zscore(data, threshold = 3):\n",
    "# In order to handle the outliers, we can check the entries' z-scores to first identify them.\n",
    "# A custom function is defined to expedite this proccess.\n",
    "    z = np.abs((data - np.mean(data)) / np.std(data))\n",
    "    outliers = np.where(z > threshold)\n",
    "    return outliers\n",
    "#########################################################\n",
    "\n",
    "# Capping the outlier values to minimize the influence of extreme values. Dropping rows is not a good idea given that we have\n",
    "# a lot of columns and very few rows, and most rows have a few NaN values somewhere along them so dropping would leave us with\n",
    "# practically zero data to work with.\n",
    "\n",
    "for col in numerical_cols:\n",
    "    outliers = detect_outliers_zscore(df_cirrhosis[col], 3)\n",
    "\n",
    "    upper_bound = df_cirrhosis[col].mean() + 3 * df_cirrhosis[col].std()\n",
    "    lower_bound = df_cirrhosis[col].mean() - 3 * df_cirrhosis[col].std()\n",
    "    \n",
    "    df_cirrhosis[col] = np.clip(df_cirrhosis[col], lower_bound, upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d476caec-2505-47b4-8c49-dff2c646640f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Turning the stage feature into an integer for our models to handle better\n",
    "\n",
    "# df_cirrhosis['Stage'] = df_cirrhosis['Stage'].astype(str) \n",
    "df_cirrhosis['Stage'] = df_cirrhosis['Stage'].astype(int) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5269f9-8c06-4d2d-89b8-65672a34627e",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e909999e-7432-434c-80d7-d5ee01c4fd25",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# importing libraries to use: Our initial approach is to test out a wide variety of algorithms and ensemble methods\n",
    "# with a moderate fold count to see which ones work best with our dataset. Afterwards, we can retry the top-performing\n",
    "# models with incrementing fold counts until we find the sweet spot of performance and accuracy.\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import log_loss, recall_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from category_encoders import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fe7c58-f3a9-4389-8acf-597af624359e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#########################################################\n",
    "def cross_validation(X, y, estimator, cv, label = ''):\n",
    "# Since we want this test to be robust, it makes sense to define a custom function to expedite some of the steps.\n",
    "# This function iterates through the folds of our stratified k-fold object with the given estimator,\n",
    "# calculates the log-loss score and returns the log-loss scores list, predictions list and a print of these alongside the model name\n",
    "    \n",
    "    # Initiating the prediction arrays and score lists to store the values for each fold\n",
    "    predictions_list = []\n",
    "    log_loss_list = []\n",
    "    recall_list = []\n",
    "    \n",
    "    for fold, (train_index, test_index) in enumerate(cv.split(X, y)):\n",
    "\n",
    "        # We clone the model instead of working on the original to avoid data bleedthrough\n",
    "        model = clone(estimator)\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Clipping the values to exclude 0 and 1 to avoid issues with the log-loss function\n",
    "        probabilities = model.predict_proba(X_test).clip(1e-15, 1 - 1e-15)\n",
    "        predictions_list.append(probabilities)\n",
    "        \n",
    "        log_loss_score = log_loss(y_test, probabilities)\n",
    "        log_loss_list.append(log_loss_score)\n",
    "\n",
    "        # Predicted classes for recall calculation\n",
    "        predicted_classes = model.predict(X_test) \n",
    "        \n",
    "        recall = recall_score(y_test, predicted_classes, average='macro')\n",
    "        recall_list.append(recall)\n",
    "    \n",
    "    print(f'| {label} | {np.mean(log_loss_list):.2f} ± {np.std(log_loss_list):.2f} | {np.mean(recall_list):.2f} ± {np.std(recall_list):.2f} |')\n",
    "    \n",
    "    return log_loss_list, predictions_list, recall_list\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81301b1-44b3-45e9-8942-ab830f3befdd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Initializing the models\n",
    "\n",
    "seed = 221192\n",
    "\n",
    "split = 10\n",
    "\n",
    "#########################################################\n",
    "def init_classifiers():\n",
    "# This function is defined to initialize our models. It is not really needed as we clone the models in the cross_validation\n",
    "# function and there is no reason to re-initialize them as long as we work with clones, but it is still nice to\n",
    "# have all the models we're going to work with in an organized spot like this.\n",
    "    \n",
    "    rf_classifier = RandomForestClassifier(random_state=seed, class_weight='balanced_subsample') # Random Forest\n",
    "\n",
    "    xgb_classifier = XGBClassifier(random_state=seed) # Gradient Boosting\n",
    "\n",
    "    svm_classifier = SVC(random_state=seed, probability=True)  # Support Vector Machine\n",
    "\n",
    "    lr_classifier = LogisticRegression(penalty='l2', C=1.0, solver='liblinear', random_state=seed, max_iter=5000) # Logistic Regression\n",
    "\n",
    "    knn_classifier = KNeighborsClassifier() # K-Nearest Neighbors\n",
    "\n",
    "    dt_classifier = DecisionTreeClassifier(random_state=seed) # Decision Tree\n",
    "\n",
    "    ada_classifier = AdaBoostClassifier(random_state=seed) # AdaBoost classifier\n",
    "\n",
    "    gnb_classifier = GaussianNB() # Gaussian Naive Bayes classifier\n",
    "    \n",
    "    return rf_classifier, xgb_classifier, svm_classifier, lr_classifier, knn_classifier, dt_classifier, ada_classifier, gnb_classifier\n",
    "#########################################################\n",
    "\n",
    "rf_classifier, xgb_classifier, svm_classifier, lr_classifier, knn_classifier, dt_classifier, ada_classifier, gnb_classifier = init_classifiers()\n",
    "\n",
    "estimators = [\n",
    "    ('rf', rf_classifier), \n",
    "    ('xgb', xgb_classifier), \n",
    "    ('svm', svm_classifier), \n",
    "    ('lr', lr_classifier), \n",
    "    ('knn', knn_classifier), \n",
    "    ('dt', dt_classifier),\n",
    "    ('ada', ada_classifier),\n",
    "    ('gnb', gnb_classifier)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0961e3-4aef-48df-b389-5ec7a6c1daac",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Defining our random seed and split count for the stratified k-fold object, which then immediately\n",
    "# gets fed into our cross_validation function\n",
    "\n",
    "skf = StratifiedKFold(n_splits = split, \n",
    "                      shuffle = True, \n",
    "                      random_state = seed\n",
    "                     )  \n",
    "\n",
    "\n",
    "# Defining the dataframes that'll store each model's score and predictions\n",
    "log_loss_frame, preds_frame, recall_frame = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "X = df_cirrhosis.drop('Stage', axis=1)\n",
    "y = df_cirrhosis['Stage']\n",
    "\n",
    "print(f'| Model | Log Loss (Mean ± Std) | Recall (Mean ± Std) |')\n",
    "print(f'|-------|-----------------------|---------------------|')\n",
    "\n",
    "# Running the cross_validation function for each model in our estimators list\n",
    "for (label, model) in estimators:\n",
    "    log_loss_frame[label], preds_frame[label], recall_frame[label] = cross_validation(X, y,\n",
    "        make_pipeline(OneHotEncoder(cols = categorical_cols), \n",
    "                      StandardScaler(), \n",
    "                      PowerTransformer(), \n",
    "                      model),\n",
    "        cv = skf,\n",
    "        label = label\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6945ef-30b4-43ee-82ec-5bf8afd6e216",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# This loop uses the stacking classifier method with our previously established methods, with the meta-learner\n",
    "# changing on each iteration.\n",
    "\n",
    "skf = StratifiedKFold(n_splits = split, \n",
    "                      shuffle = True, \n",
    "                      random_state = seed\n",
    "                     )  \n",
    "\n",
    "\n",
    "log_loss_frame_stacked, preds_frame_stacked, recall_frame_stacked = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "X = df_cirrhosis.drop('Stage', axis=1)\n",
    "y = df_cirrhosis['Stage']\n",
    "\n",
    "print(f'| Meta-Learner | Log Loss (Mean ± Std) | Recall (Mean ± Std) |')\n",
    "print(f'|--------------|-----------------------|---------------------|')\n",
    "\n",
    "for i, (label, meta_learner) in enumerate(estimators):\n",
    "\n",
    "    # Creating a new list of our models to exclude the meta learner from the initial learners.\n",
    "    initial_learners = []\n",
    "    for j, (label2, estimator) in enumerate(estimators):\n",
    "        if i != j:\n",
    "            initial_learners.append((label2, estimator))\n",
    "            \n",
    "    stacking_classifier = StackingClassifier(estimators = initial_learners, \n",
    "                                             final_estimator = meta_learner \n",
    "                                            )\n",
    "    \n",
    "    log_loss_frame_stacked[label], preds_frame_stacked[label], recall_frame_stacked[label] = cross_validation(X, y,\n",
    "        make_pipeline(OneHotEncoder(cols = categorical_cols), \n",
    "                      StandardScaler(), \n",
    "                      PowerTransformer(), \n",
    "                      stacking_classifier),\n",
    "        cv = skf,\n",
    "        label = label\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c5a85e-3fec-40b5-b198-287cb9df62e9",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7b9997-a29a-43f6-91b9-cda0f2f75cbc",
   "metadata": {},
   "source": [
    "In the end, we have the following log loss and recall values for our models:\n",
    "\n",
    "| Model | Log Loss (Mean ± Std) | Recall (Mean ± Std) |\n",
    "|-------|-----------------------|---------------------|\n",
    "| rf | 1.16 ± 0.26 | 0.36 ± 0.05 |\n",
    "| xgb | 1.54 ± 0.26 | 0.39 ± 0.05 |\n",
    "| svm | 1.08 ± 0.06 | 0.35 ± 0.04 |\n",
    "| lr | 1.12 ± 0.13 | 0.38 ± 0.05 |\n",
    "| knn | 5.32 ± 1.07 | 0.37 ± 0.09 |\n",
    "| dt | 19.74 ± 2.21 | 0.35 ± 0.09 |\n",
    "| ada | 1.36 ± 0.00 | 0.38 ± 0.04 |\n",
    "| gnb | 23.91 ± 2.91 | 0.31 ± 0.05 |\n",
    "\n",
    "| Meta-Learner | Log Loss (Mean ± Std) | Recall (Mean ± Std) |\n",
    "|--------------|-----------------------|---------------------|\n",
    "| rf | 1.33 ± 0.49 | 0.35 ± 0.07 |\n",
    "| xgb | 1.68 ± 0.22 | 0.36 ± 0.09 |\n",
    "| svm | 1.11 ± 0.05 | 0.35 ± 0.03 |\n",
    "| lr | 1.10 ± 0.08 | 0.34 ± 0.03 |\n",
    "| knn | 6.34 ± 1.58 | 0.34 ± 0.06 |\n",
    "| dt | 21.74 ± 2.11 | 0.28 ± 0.05 |\n",
    "| ada | 1.36 ± 0.00 | 0.35 ± 0.05 |\n",
    "| gnb | 4.68 ± 1.15 | 0.49 ± 0.09 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458ca3bb-5fbd-4cbb-981a-751c911f364c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Visualizing the log loss and recall values for our tests\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12)) \n",
    "\n",
    "### Model Plots\n",
    "log_loss_mean_model = log_loss_frame.mean()\n",
    "log_loss_std_model = log_loss_frame.std()\n",
    "sorted_models_log_loss = log_loss_mean_model.sort_values().index\n",
    "\n",
    "recall_mean_model = recall_frame.mean()\n",
    "recall_std_model = recall_frame.std()\n",
    "sorted_models_recall = recall_mean_model.sort_values(ascending=False).index\n",
    "\n",
    "# Log Loss Plot\n",
    "\n",
    "sns.barplot(ax= axes[0,0],\n",
    "            x = log_loss_mean_model[sorted_models_log_loss],\n",
    "            y = sorted_models_log_loss,\n",
    "            color='skyblue')\n",
    "\n",
    "axes[0,0].errorbar(x = log_loss_mean_model[sorted_models_log_loss],\n",
    "                 y   = sorted_models_log_loss,\n",
    "                 xerr= log_loss_std_model[sorted_models_log_loss],\n",
    "                 fmt='o',\n",
    "                 color='black',\n",
    "                 capsize=5)\n",
    "\n",
    "axes[0,0].set_xlabel(\"Mean Log Loss\")\n",
    "axes[0,0].set_ylabel(\"Models\")\n",
    "axes[0,0].set_title(\"Mean Log Loss of Different Models\")\n",
    "\n",
    "# Recall Plot\n",
    "\n",
    "sns.barplot(ax= axes[0,1],\n",
    "            x = recall_mean_model[sorted_models_recall],\n",
    "            y = sorted_models_recall,\n",
    "            color='lightgreen')\n",
    "\n",
    "axes[0,1].errorbar(x = recall_mean_model[sorted_models_recall],\n",
    "                 y   = sorted_models_recall,\n",
    "                 xerr= recall_std_model[sorted_models_recall],\n",
    "                 fmt='o', color='black', capsize=5)\n",
    "\n",
    "axes[0,1].set_xlabel(\"Mean Recall\")\n",
    "axes[0,1].set_ylabel(\"Models\")\n",
    "axes[0,1].set_title(\"Mean Recall of Different Models\")\n",
    "\n",
    "\n",
    "### Meta Learner Plots\n",
    "log_loss_mean_stacked= log_loss_frame_stacked.mean()\n",
    "log_loss_std_stacked = log_loss_frame_stacked.std()\n",
    "sorted_meta_log_loss = log_loss_mean_stacked.sort_values().index\n",
    "\n",
    "recall_mean_stacked= recall_frame_stacked.mean()\n",
    "recall_std_stacked = recall_frame_stacked.std()\n",
    "sorted_meta_recall = recall_mean_stacked.sort_values(ascending=False).index\n",
    "\n",
    "# Log Loss Plot\n",
    "\n",
    "sns.barplot(ax= axes[1,0],\n",
    "            x = log_loss_mean_stacked[sorted_meta_log_loss],\n",
    "            y = sorted_meta_log_loss,\n",
    "            color='skyblue')\n",
    "\n",
    "axes[1,0].errorbar(x = log_loss_mean_stacked[sorted_meta_log_loss],\n",
    "                 y   = sorted_meta_log_loss,\n",
    "                 xerr= log_loss_std_stacked[sorted_meta_log_loss],\n",
    "                 fmt ='o',\n",
    "                 color='black',\n",
    "                 capsize=5)\n",
    "\n",
    "axes[1,0].set_xlabel(\"Mean Log Loss\")\n",
    "axes[1,0].set_ylabel(\"Meta Learners\")\n",
    "axes[1,0].set_title(\"Mean Log Loss of Different Meta Learners\")\n",
    "\n",
    "# Recall Plot\n",
    "\n",
    "sns.barplot(ax= axes[1,1],\n",
    "            x = recall_mean_stacked[sorted_meta_recall],\n",
    "            y = sorted_meta_recall,\n",
    "            color='lightgreen')\n",
    "\n",
    "axes[1,1].errorbar(x = recall_mean_stacked[sorted_meta_recall],\n",
    "                 y   = sorted_meta_recall,\n",
    "                 xerr= recall_std_stacked[sorted_models_recall],\n",
    "                 fmt='o', color='black', capsize=5)\n",
    "\n",
    "axes[1,1].set_xlabel(\"Mean Recall\")\n",
    "axes[1,1].set_ylabel(\"Meta Learners\")\n",
    "axes[1,1].set_title(\"Mean Recall of Different Meta Learners\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7101bb05-9b10-42ef-9976-fc8089588ef4",
   "metadata": {},
   "source": [
    "Looking at our results, most individual models operate on a similar level, with our best choices being (in order of descending recall):\n",
    "\n",
    "\n",
    "| Model      | Log Loss (Mean ± Std) | Recall (Mean ± Std) |\n",
    "| ---------- | --------------------- | ------------------- |\n",
    "| Gaussian Naive Bayes (as meta-learner) | 4.68 ± 1.15 | 0.49 ± 0.09 |\n",
    "| Gradient Boosting | 1.54 ± 0.26 | 0.39 ± 0.05 |\n",
    "| Logistic Regression | 1.12 ± 0.13 | 0.38 ± 0.05 |\n",
    "| Support Vector Machine | 1.08 ± 0.06 | 0.35 ± 0.04 |\n",
    "\n",
    "\n",
    "Since the goal of this project is to identify an illness, maximizing true positives at the expense of disproportionately increasing false positives\n",
    "can be accepted, so Gaussian Naive Bayes as a meta-learner for our other models might be the best choice depending on preference.\n",
    "Determining how much importance we put on maximizing true positives over minimizing false positives, we could also check the models' F1 score with\n",
    "a high beta value to find an \"objective\" best choice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
